{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac9e839-e3ac-4b95-9dc7-7414c0effd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os \n",
    "import os\n",
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from collections import Counter\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031259b7-826c-4049-924b-5979302b35fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import VideoMAEImageProcessor\n",
    "from transformers import AutoConfig, AutoModelForVideoClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b17478-4926-45aa-8120-47b59931a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2, reduction='mean'):\n",
    "        \"\"\"\n",
    "        Focal Loss для решения проблемы дисбаланса классов.\n",
    "        :param alpha: Веса классов. Если None, все классы считаются равноважными.\n",
    "        :param gamma: Фокусирующий параметр. Чем выше gamma, тем больше фокус на сложных примерах.\n",
    "        :param reduction: Способ агрегации потерь ('none', 'mean', 'sum').\n",
    "        \"\"\"\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # Применяем логит к целям\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n",
    "        pt = torch.exp(-ce_loss)  # Вероятность предсказания правильного класса\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6794dc89-0a09-4481-bad8-4b9cd231bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, root_dir, model_name, max_frames=8, transform=None, video_files=None, video_labels=None, class_to_idx=None):\n",
    "        self.model_name = model_name\n",
    "        self.max_frames = max_frames\n",
    "        self.transform = transform\n",
    "\n",
    "        if video_files is not None and video_labels is not None:\n",
    "            self.video_files = video_files\n",
    "            self.video_labels = video_labels\n",
    "\n",
    "            if class_to_idx is not None:\n",
    "                self.class_to_idx = class_to_idx\n",
    "                self.class_names = sorted(class_to_idx, key=class_to_idx.get)\n",
    "            else:\n",
    "                raise ValueError(\"Если предоставлены video_files и video_labels, необходимо также предоставить class_to_idx.\")\n",
    "        else:\n",
    "            self.root_dir = root_dir\n",
    "            self.class_names = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
    "            self.class_to_idx = {class_name: idx for idx, class_name in enumerate(self.class_names)}\n",
    "\n",
    "            self.video_files = []\n",
    "            self.video_labels = []\n",
    "\n",
    "            for class_name in self.class_names:\n",
    "                class_dir = os.path.join(root_dir, class_name)\n",
    "                for video_file in os.listdir(class_dir):\n",
    "                    if video_file.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "                        video_path = os.path.join(class_dir, video_file)\n",
    "                        self.video_files.append(video_path)\n",
    "                        self.video_labels.append(self.class_to_idx[class_name])\n",
    "\n",
    "        self.feature_extractor = VideoMAEImageProcessor.from_pretrained(self.model_name)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.video_files[idx]\n",
    "        label = self.video_labels[idx]\n",
    "\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        frames = []\n",
    "        frame_count = 0\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break  \n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "            frame_count += 1\n",
    "            if frame_count == self.max_frames:\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        if len(frames) < self.max_frames:\n",
    "            last_frame = frames[-1]\n",
    "            while len(frames) < self.max_frames:\n",
    "                frames.append(last_frame)\n",
    "\n",
    "        if self.transform:\n",
    "            frames = [self.transform(frame) for frame in frames]\n",
    "\n",
    "        frames = [np.array(frame) for frame in frames]\n",
    "\n",
    "        inputs = self.feature_extractor(frames, return_tensors=\"pt\")\n",
    "\n",
    "        return inputs, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b68beb6-a119-40c7-be9f-1026b8cd7039",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/timesformer-base-finetuned-k400\"  \n",
    "batch_size = 4                                        \n",
    "epochs = 5                                           \n",
    "learning_rate = 5e-5                               \n",
    "max_frames = 8                                    \n",
    "num_workers = 0                                    \n",
    "save_path = \"best_model.pt\"                           \n",
    "data_dir = r\"D:\\sports activities\"                    \n",
    "\n",
    "train_dir = data_dir\n",
    "\n",
    "if not os.path.isdir(train_dir):\n",
    "    raise ValueError(f\"Тренировочная директория не найдена: {train_dir}\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),  \n",
    "])\n",
    "\n",
    "print(\"Загрузка конфигурации и модели...\")\n",
    "\n",
    "num_classes = 6\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name, num_labels=num_classes)\n",
    "\n",
    "model = AutoModelForVideoClassification.from_pretrained(\n",
    "    model_name,\n",
    "    config=config,\n",
    "    ignore_mismatched_sizes=True  \n",
    ")\n",
    "\n",
    "print(\"Сбор всех видеофайлов и меток из train_dir...\")\n",
    "full_dataset = VideoDataset(root_dir=train_dir, model_name=model_name, max_frames=max_frames, transform=transform)\n",
    "all_video_files = full_dataset.video_files\n",
    "all_video_labels = full_dataset.video_labels\n",
    "class_to_idx = full_dataset.class_to_idx\n",
    "class_names = full_dataset.class_names\n",
    "\n",
    "print(\"Разделение данных на тренировочную и валидационную выборки...\")\n",
    "train_files, val_files, train_labels, val_labels = train_test_split(\n",
    "    all_video_files,\n",
    "    all_video_labels,\n",
    "    test_size=0.2,\n",
    "    stratify=all_video_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Количество тренировочных видео: {len(train_files)}\")\n",
    "print(f\"Количество валидационных видео: {len(val_files)}\")\n",
    "print(f\"Число классов: {len(class_names)}\")\n",
    "\n",
    "print(\"Вычисление весов классов для FocalLoss...\")\n",
    "label_counts = Counter(train_labels)\n",
    "total_counts = sum(label_counts.values())\n",
    "num_classes = len(class_names)\n",
    "\n",
    "class_weights = []\n",
    "for i in range(num_classes):\n",
    "    count = label_counts.get(i, 0)\n",
    "    if count > 0:\n",
    "        class_weights.append(total_counts / (num_classes * count))\n",
    "    else:\n",
    "        class_weights.append(1.0)  \n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "print(f\"Вес каждого класса: {class_weights}\")\n",
    "\n",
    "# ======= Создание Тренировочного и Валидационного Dataset =======\n",
    "print(\"Создание тренировочного и валидационного Dataset...\")\n",
    "train_dataset = VideoDataset(\n",
    "    root_dir=None,\n",
    "    model_name=model_name,\n",
    "    max_frames=max_frames,\n",
    "    video_files=train_files,\n",
    "    video_labels=train_labels,\n",
    "    class_to_idx=class_to_idx,\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset = VideoDataset(\n",
    "    root_dir=None,\n",
    "    model_name=model_name,\n",
    "    max_frames=max_frames,\n",
    "    video_files=val_files,\n",
    "    video_labels=val_labels,\n",
    "    class_to_idx=class_to_idx,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(\"Создание DataLoader...\")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "print(f\"Используемое устройство: {device}\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_training_steps = epochs * len(train_dataloader)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "\n",
    "loss_fn = FocalLoss(alpha=class_weights, gamma=2, reduction='mean')\n",
    "\n",
    "best_val_f1 = 0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nЭпоха {epoch + 1}/{epochs}\")\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "    # ---- Обучение ----\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    all_train_preds = []\n",
    "    all_train_labels = []\n",
    "\n",
    "    train_progress = tqdm(train_dataloader, desc=\"Обучение\", leave=False)\n",
    "    for batch in train_progress:\n",
    "        try:\n",
    "            inputs, labels = batch\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            labels = labels.to(device)\n",
    "            inputs['pixel_values'] = inputs['pixel_values'].squeeze(1)\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss = loss_fn(logits, labels)\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            all_train_preds.extend(preds.detach().cpu().numpy())\n",
    "            all_train_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "            train_progress.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при обработке батча: {e}\")\n",
    "            continue\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    train_accuracy = accuracy_score(all_train_labels, all_train_preds)\n",
    "    train_f1 = f1_score(all_train_labels, all_train_preds, average='weighted')\n",
    "\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy:.4f} | Train F1: {train_f1:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    all_val_preds = []\n",
    "    all_val_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_progress = tqdm(val_dataloader, desc=\"Валидация\", leave=False)\n",
    "        for batch in val_progress:\n",
    "            try:\n",
    "                inputs, labels = batch\n",
    "                inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "                labels = labels.to(device)\n",
    "                inputs['pixel_values'] = inputs['pixel_values'].squeeze(1)\n",
    "\n",
    "                outputs = model(**inputs)\n",
    "                logits = outputs.logits\n",
    "\n",
    "                loss = loss_fn(logits, labels)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                preds = torch.argmax(logits, dim=-1)\n",
    "                all_val_preds.extend(preds.detach().cpu().numpy())\n",
    "                all_val_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при обработке батча валидации: {e}\")\n",
    "                continue\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    val_accuracy = accuracy_score(all_val_labels, all_val_preds)\n",
    "    val_f1 = f1_score(all_val_labels, all_val_preds, average='weighted')\n",
    "\n",
    "    print(f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.4f} | Val F1: {val_f1:.4f}\")\n",
    "\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"Сохранена лучшая модель с Val F1: {best_val_f1:.4f}\")\n",
    "\n",
    "print(\"\\nОбучение завершено.\")\n",
    "print(f\"Лучший Val F1: {best_val_f1:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
